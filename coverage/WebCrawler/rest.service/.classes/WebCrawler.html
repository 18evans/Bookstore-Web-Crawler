


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html id="htmlId">
<head>
  <title>Coverage Report :: WebCrawler</title>
  <style type="text/css">
    @import "../../.css/coverage.css";
  </style>
</head>

<body>
<div class="header"></div>

<div class="content">
<div class="breadCrumbs">
    [ <a href="../../index.html">all classes</a> ]
    [ <a href="../index.html">rest.service</a> ]
</div>

<h1>Coverage Summary for Class: WebCrawler (rest.service)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">WebCrawler</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (1/ 1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    100%
  </span>
  <span class="absValue">
    (15/ 15)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    98.4%
  </span>
  <span class="absValue">
    (60/ 61)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<div class="sourceCode"><i>1</i>&nbsp;package rest.service;
<i>2</i>&nbsp;
<i>3</i>&nbsp;import org.apache.commons.lang3.StringUtils;
<i>4</i>&nbsp;import org.jsoup.Jsoup;
<i>5</i>&nbsp;import org.jsoup.nodes.Document;
<i>6</i>&nbsp;import org.jsoup.nodes.Element;
<i>7</i>&nbsp;import org.jsoup.select.Elements;
<i>8</i>&nbsp;import rest.service.model.Item;
<i>9</i>&nbsp;import rest.service.model.Movies;
<i>10</i>&nbsp;
<i>11</i>&nbsp;import java.io.IOException;
<i>12</i>&nbsp;import java.net.URL;
<i>13</i>&nbsp;import java.util.Collections;
<i>14</i>&nbsp;import java.util.HashSet;
<i>15</i>&nbsp;import java.util.Set;
<i>16</i>&nbsp;
<i>17</i>&nbsp;public class WebCrawler {
<i>18</i>&nbsp;
<i>19</i>&nbsp;    private Statistic statistic;
<i>20</i>&nbsp;    private URL url;
<i>21</i>&nbsp;    private Scraper scraper;
<i>22</i>&nbsp;    private final Set&lt;URL&gt; exploredUrls;
<i>23</i>&nbsp;    private final Set&lt;URL&gt; toBeExploredUrls;
<i>24</i>&nbsp;    private Set&lt;Item&gt; foundItems;
<i>25</i>&nbsp;
<b class="fc"><i>26</i>&nbsp;    public WebCrawler(URL url, String keyword, Item type) {</b>
<b class="fc"><i>27</i>&nbsp;        this.url = url;</b>
<b class="fc"><i>28</i>&nbsp;        if (keyword == null || keyword.equals(&quot;&quot;)) {</b>
<b class="fc"><i>29</i>&nbsp;            throw new IllegalArgumentException();</b>
<i>30</i>&nbsp;        }
<b class="fc"><i>31</i>&nbsp;        statistic = new Statistic(type, keyword);</b>
<b class="fc"><i>32</i>&nbsp;        exploredUrls = new HashSet&lt;&gt;();</b>
<b class="fc"><i>33</i>&nbsp;        toBeExploredUrls = Collections.singleton(url);</b>
<b class="fc"><i>34</i>&nbsp;        foundItems = new HashSet&lt;&gt;();</b>
<b class="fc"><i>35</i>&nbsp;        this.scraper = new Scraper();</b>
<b class="fc"><i>36</i>&nbsp;    }</b>
<i>37</i>&nbsp;
<i>38</i>&nbsp;    /***
<i>39</i>&nbsp;     * Set the Statistic object - for mocking purpose
<i>40</i>&nbsp;     * @param statistic
<i>41</i>&nbsp;     */
<i>42</i>&nbsp;    public void setStatistic(Statistic statistic) {
<b class="fc"><i>43</i>&nbsp;        this.statistic = statistic;</b>
<b class="fc"><i>44</i>&nbsp;    }</b>
<i>45</i>&nbsp;
<i>46</i>&nbsp;    /**
<i>47</i>&nbsp;     * Method calls private crawl which will recursively go through the URL,
<i>48</i>&nbsp;     * looking for the specified objects either by using BFS or DFS searching algorithm.
<i>49</i>&nbsp;     *
<i>50</i>&nbsp;     * @return A Set Collection of the Item
<i>51</i>&nbsp;     */
<i>52</i>&nbsp;    public Set&lt;Item&gt; startCrawler() throws IOException {
<b class="fc"><i>53</i>&nbsp;        return crawl(toBeExploredUrls);</b>
<i>54</i>&nbsp;    }
<i>55</i>&nbsp;
<i>56</i>&nbsp;    /**
<i>57</i>&nbsp;     * Method wil recursively go through the passed collection of url parameter,
<i>58</i>&nbsp;     * until it reaches the end recursively adding it&#39;s finding to its return type of
<i>59</i>&nbsp;     * a Set of Item objects.
<i>60</i>&nbsp;     *
<i>61</i>&nbsp;     * @param urls the url&#39;s left to go through
<i>62</i>&nbsp;     * @return the found Items
<i>63</i>&nbsp;     */
<i>64</i>&nbsp;    private Set&lt;Item&gt; crawl(Set&lt;URL&gt; urls) {
<b class="fc"><i>65</i>&nbsp;        urls.removeAll(this.exploredUrls);</b>
<b class="fc"><i>66</i>&nbsp;        if (!urls.isEmpty()) {</b>
<b class="fc"><i>67</i>&nbsp;            this.exploredUrls.addAll(urls);</b>
<b class="fc"><i>68</i>&nbsp;            final Set&lt;URL&gt; newUrls = new HashSet&lt;&gt;();</b>
<i>69</i>&nbsp;            try {
<b class="fc"><i>70</i>&nbsp;                for (final URL url : toBeExploredUrls) {</b>
<b class="fc"><i>71</i>&nbsp;                    this.statistic.increasePagesExplored();</b>
<b class="fc"><i>72</i>&nbsp;                    final Document document = Jsoup.connect(url.toString()).get();</b>
<b class="fc"><i>73</i>&nbsp;                    final Elements urlsOnPage = document.select(&quot;a[href]&quot;);</b>
<b class="fc"><i>74</i>&nbsp;                    Item newFoundItem = (Item) scraper.scrapeAndGetItem(document);</b>
<b class="fc"><i>75</i>&nbsp;                    if (newFoundItem != null &amp;&amp; foundItems.stream().noneMatch(o -&gt; o.compareTo(newFoundItem))) {</b>
<i>76</i>&nbsp;                        //do not add if no new found element or an element with same properties exists
<b class="fc"><i>77</i>&nbsp;                        foundItems.add(newFoundItem);</b>
<i>78</i>&nbsp;                    }
<b class="fc"><i>79</i>&nbsp;                    for (final Element element : urlsOnPage) {</b>
<b class="fc"><i>80</i>&nbsp;                        final String urlText = element.attr(&quot;abs:href&quot;);</b>
<b class="fc"><i>81</i>&nbsp;                        final URL discoveredUrl = new URL(urlText);</b>
<b class="fc"><i>82</i>&nbsp;                        newUrls.add(discoveredUrl);</b>
<b class="fc"><i>83</i>&nbsp;                    }</b>
<b class="fc"><i>84</i>&nbsp;                }</b>
<b class="nc"><i>85</i>&nbsp;            } catch (Exception ex) {</b>
<i>86</i>&nbsp;
<b class="fc"><i>87</i>&nbsp;            }</b>
<b class="fc"><i>88</i>&nbsp;            this.statistic.increaseSearchDepth();</b>
<b class="fc"><i>89</i>&nbsp;            return crawl(newUrls);</b>
<i>90</i>&nbsp;        } else {
<i>91</i>&nbsp;            // filter all the item founds to match the searching criteria
<b class="fc"><i>92</i>&nbsp;            return process(foundItems);</b>
<i>93</i>&nbsp;        }
<i>94</i>&nbsp;    }
<i>95</i>&nbsp;
<i>96</i>&nbsp;    /***
<i>97</i>&nbsp;     * Filter out all un-matched item and return the collection of close-matched items
<i>98</i>&nbsp;     * @param foundItems - the raw result collection
<i>99</i>&nbsp;     * @return
<i>100</i>&nbsp;     */
<i>101</i>&nbsp;    private Set&lt;Item&gt; process(Set&lt;Item&gt; foundItems) {
<b class="fc"><i>102</i>&nbsp;        Set&lt;Item&gt; result = new HashSet&lt;&gt;();</b>
<b class="fc"><i>103</i>&nbsp;        String targetKeyword = this.statistic.getKeyword();</b>
<i>104</i>&nbsp;
<b class="fc"><i>105</i>&nbsp;        for (Item i : foundItems) {</b>
<b class="fc"><i>106</i>&nbsp;            if (StringUtils.isBlank(targetKeyword) ||</b>
<b class="fc"><i>107</i>&nbsp;                    i.getTitle().contains(targetKeyword) ||</b>
<b class="fc"><i>108</i>&nbsp;                    i.getGenre().contains(targetKeyword) ||</b>
<b class="fc"><i>109</i>&nbsp;                    i.getYear().toString().contains(targetKeyword) ||</b>
<b class="fc"><i>110</i>&nbsp;                    i.getFormat().contains(targetKeyword)) {</b>
<b class="fc"><i>111</i>&nbsp;                result.add(i);</b>
<i>112</i>&nbsp;            }
<b class="fc"><i>113</i>&nbsp;        }</b>
<i>114</i>&nbsp;
<b class="fc"><i>115</i>&nbsp;        return result;</b>
<i>116</i>&nbsp;    }
<i>117</i>&nbsp;
<i>118</i>&nbsp;    /***
<i>119</i>&nbsp;     * Return the initial url
<i>120</i>&nbsp;     * @return
<i>121</i>&nbsp;     */
<i>122</i>&nbsp;    public String getInitUrl() {
<b class="fc"><i>123</i>&nbsp;        return this.url.toString();</b>
<i>124</i>&nbsp;    }
<i>125</i>&nbsp;
<i>126</i>&nbsp;    /***
<i>127</i>&nbsp;     * return the keyword
<i>128</i>&nbsp;     * @return
<i>129</i>&nbsp;     */
<i>130</i>&nbsp;    public String getKeyword() {
<b class="fc"><i>131</i>&nbsp;        return statistic.getKeyword();</b>
<i>132</i>&nbsp;    }
<i>133</i>&nbsp;
<i>134</i>&nbsp;    public Item getItem() {
<b class="fc"><i>135</i>&nbsp;        return statistic.getType();</b>
<i>136</i>&nbsp;    }
<i>137</i>&nbsp;
<i>138</i>&nbsp;    public Statistic getStatistic() {
<b class="fc"><i>139</i>&nbsp;        return statistic;</b>
<i>140</i>&nbsp;    }
<i>141</i>&nbsp;
<i>142</i>&nbsp;    public Set&lt;URL&gt; getExploredUrls() {
<b class="fc"><i>143</i>&nbsp;        return exploredUrls;</b>
<i>144</i>&nbsp;    }
<i>145</i>&nbsp;
<i>146</i>&nbsp;
<i>147</i>&nbsp;    public Set&lt;URL&gt; getToBeExploredUrls() {
<b class="fc"><i>148</i>&nbsp;        return toBeExploredUrls;</b>
<i>149</i>&nbsp;    }
<i>150</i>&nbsp;
<i>151</i>&nbsp;
<i>152</i>&nbsp;    /***
<i>153</i>&nbsp;     * Set the Scraper object - for mocking purpose
<i>154</i>&nbsp;     * @param scraper
<i>155</i>&nbsp;     */
<i>156</i>&nbsp;    public void setScraper(Scraper scraper) {
<b class="fc"><i>157</i>&nbsp;        this.scraper = scraper;</b>
<b class="fc"><i>158</i>&nbsp;    }</b>
<i>159</i>&nbsp;
<i>160</i>&nbsp;    /***
<i>161</i>&nbsp;     * Change the target keyword and reset the statistic to start a new crawling process.
<i>162</i>&nbsp;     * @param newKeyword
<i>163</i>&nbsp;     */
<i>164</i>&nbsp;    public void changeKeyword(String newKeyword) {
<b class="fc"><i>165</i>&nbsp;        this.statistic.changeKeyword(newKeyword);</b>
<b class="fc"><i>166</i>&nbsp;        this.statistic.resetData();</b>
<b class="fc"><i>167</i>&nbsp;    }</b>
<i>168</i>&nbsp;
<i>169</i>&nbsp;    /***
<i>170</i>&nbsp;     * Change the target type and reset the statistic to start a new crawling process
<i>171</i>&nbsp;     * @param newType
<i>172</i>&nbsp;     */
<i>173</i>&nbsp;    public void changeType(Item newType) {
<b class="fc"><i>174</i>&nbsp;        this.statistic.changeTargetType(newType);</b>
<b class="fc"><i>175</i>&nbsp;        this.statistic.resetData();</b>
<b class="fc"><i>176</i>&nbsp;    }</b>
<i>177</i>&nbsp;
<i>178</i>&nbsp;    /***
<i>179</i>&nbsp;     * Retunr the current search depth after the crawling process already finished
<i>180</i>&nbsp;     * @return
<i>181</i>&nbsp;     */
<i>182</i>&nbsp;    public Integer getSearchDepth() {
<b class="fc"><i>183</i>&nbsp;        return this.statistic.getSearchDepth();</b>
<i>184</i>&nbsp;    }
<i>185</i>&nbsp;}
</div>
</div>

<div class="footer">
    
    <div style="float:right;">generated on 2019-06-19 03:06</div>
</div>
</body>
</html>
